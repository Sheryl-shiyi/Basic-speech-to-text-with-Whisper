{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Whisper Transcription (HTTP-only) in OpenShift\n",
        "\n",
        "This notebook wraps a **minimal HTTP flow** for sending local audio files to your **OpenAI-compatible Whisper** service in OpenShift.\n",
        "\n",
        "**What you get**\n",
        "- Clear configuration section\n",
        "- Small helper to list audio files\n",
        "- A `requests`-based function that posts to `/v1/audio/transcriptions`\n",
        "- Simple ipywidgets UI to pick, play, and transcribe files\n",
        "\n",
        "> **Scope**: This version intentionally uses only the raw HTTP approach (no OpenAI SDK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "- Run this where the service DNS (e.g., `*.svc.cluster.local`) is reachable.\n",
        "- Your Whisper service should implement `POST /v1/audio/transcriptions` (OpenAI-compatible).\n",
        "- Put a few test audio files in the configured folder (default: `/opt/app-root/src/audio_data/`).\n",
        "- If your endpoint requires auth, set an environment variable `OPENAI_API_KEY` before running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: install dependencies if needed\n",
        "# %pip install --quiet --upgrade requests ipywidgets\n",
        "# If running in JupyterLab, enable widgets once (restart kernel might be required):\n",
        "# %pip install --quiet jupyterlab-widgets ipywidgets\n",
        "# %jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Configuration\n",
        "Update these values to match your environment and directory layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIG ===\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Whisper endpoint (adjust port/scheme to match your service)\n",
        "WHISPER_HOST = \"http://whisper-large-v3-predictor.whisper-proj.svc.cluster.local:8080\"\n",
        "WHISPER_API = f\"{WHISPER_HOST}/v1/audio/transcriptions\"\n",
        "\n",
        "# Model + auth (if any)\n",
        "WHISPER_MODEL = \"whisper-large-v3\"\n",
        "# Optional auth: set via env var OPENAI_API_KEY (or assign a token string here)\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "# Local audio directory (where your samples are)\n",
        "LOCAL_AUDIO_DIR = Path(\"/opt/app-root/src/audio_data/\")  # change to your path\n",
        "\n",
        "# Audio extensions to show in UI\n",
        "AUDIO_EXTS = (\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\", \".aac\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Imports & Utilities\n",
        "We keep helpers small and focused."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === IMPORTS & UTILITIES ===\n",
        "import requests\n",
        "from typing import List\n",
        "from IPython.display import Audio\n",
        "\n",
        "def list_local_audio_files(directory: Path, exts=AUDIO_EXTS) -> List[Path]:\n",
        "    directory = Path(directory)\n",
        "    return sorted([p for p in directory.glob(\"*\") if p.suffix.lower() in exts and p.is_file()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Transcription function (HTTP via `requests`)\n",
        "Sends a **multipart/form-data** POST to the Whisper endpoint. Returns the transcript text when available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_with_whisper(\n",
        "    local_audio_path: Path,\n",
        "    model_name: str = WHISPER_MODEL,\n",
        "    api_url: str = WHISPER_API,\n",
        "    api_key: str | None = OPENAI_API_KEY,\n",
        "    timeout: int = 180,\n",
        "):\n",
        "    \"\"\"Send a local file to an OpenAI-compatible Whisper endpoint and return transcript text (or raw JSON).\"\"\"\n",
        "    headers = {}\n",
        "    if api_key:\n",
        "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "    \n",
        "    # Use a context manager to avoid leaving the file handle open\n",
        "    with open(local_audio_path, \"rb\") as f:\n",
        "        files = {\"file\": (local_audio_path.name, f, \"application/octet-stream\")}\n",
        "        data = {\"model\": model_name}\n",
        "        resp = requests.post(api_url, headers=headers, files=files, data=data, timeout=timeout)\n",
        "\n",
        "    resp.raise_for_status()\n",
        "    js = resp.json()\n",
        "    if \"text\" in js:\n",
        "        return js[\"text\"]\n",
        "    if isinstance(js, dict) and \"choices\" in js and js[\"choices\"] and \"text\" in js[\"choices\"][0]:\n",
        "        return js[\"choices\"][0][\"text\"]\n",
        "    return js  # fallback if the server returns a different shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) UI â€” Pick, play, and transcribe\n",
        "Use **Refresh** to scan the folder, **Play** to preview, and **Transcribe** to send the file to Whisper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === UI WIDGETS ===\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Inputs\n",
        "dir_text = widgets.Text(value=str(LOCAL_AUDIO_DIR), description=\"Folder:\", layout=widgets.Layout(width=\"60%\"))\n",
        "refresh_btn = widgets.Button(description=\"Refresh\", icon=\"refresh\")\n",
        "file_dd = widgets.Dropdown(options=[], description=\"File:\", layout=widgets.Layout(width=\"70%\"))\n",
        "\n",
        "# Actions\n",
        "play_btn = widgets.Button(description=\"Play\", icon=\"play\")\n",
        "transcribe_btn = widgets.Button(description=\"Transcribe\", icon=\"microphone\")\n",
        "\n",
        "# Outputs\n",
        "status_out = widgets.Output()\n",
        "audio_out = widgets.Output()\n",
        "text_out = widgets.Output()\n",
        "\n",
        "def refresh_files(_=None):\n",
        "    folder = Path(dir_text.value).expanduser()\n",
        "    files = list_local_audio_files(folder)\n",
        "    file_dd.options = files\n",
        "    with status_out:\n",
        "        clear_output(wait=True)\n",
        "        if files:\n",
        "            print(f\"Found {len(files)} audio file(s) in {folder}\")\n",
        "        else:\n",
        "            print(f\"No audio files found in {folder}\")\n",
        "\n",
        "def play_audio(_=None):\n",
        "    sel = file_dd.value\n",
        "    if not sel:\n",
        "        return\n",
        "    with audio_out:\n",
        "        clear_output(wait=True)\n",
        "        display(Audio(filename=str(sel), autoplay=False))\n",
        "\n",
        "def run_transcription(_=None):\n",
        "    sel = file_dd.value\n",
        "    if not sel:\n",
        "        return\n",
        "    with status_out:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Transcribing: {Path(sel).name}\")\n",
        "    try:\n",
        "        txt = transcribe_with_whisper(Path(sel))\n",
        "        with text_out:\n",
        "            clear_output(wait=True)\n",
        "            print(\"=== Transcript ===\")\n",
        "            print(txt if isinstance(txt, str) else str(txt))\n",
        "        with status_out:\n",
        "            clear_output(wait=True)\n",
        "            print(\"Done.\")\n",
        "    except Exception as e:\n",
        "        with text_out:\n",
        "            clear_output(wait=True)\n",
        "            print(\"Transcription failed:\", e)\n",
        "\n",
        "refresh_btn.on_click(refresh_files)\n",
        "play_btn.on_click(play_audio)\n",
        "transcribe_btn.on_click(run_transcription)\n",
        "\n",
        "# Render the UI\n",
        "display(widgets.HBox([dir_text, refresh_btn]))\n",
        "display(file_dd)\n",
        "display(widgets.HBox([play_btn, transcribe_btn]))\n",
        "display(status_out, audio_out, text_out)\n",
        "\n",
        "# initial file load\n",
        "refresh_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) (Optional) Quick smoke test\n",
        "Runs transcription on the currently selected file (or the first file in the folder if nothing is selected)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_file = file_dd.value or (list_local_audio_files(LOCAL_AUDIO_DIR)[:1] or [None])[0]\n",
        "if test_file:\n",
        "    print(f\"Transcribing (smoke test): {Path(test_file).name}\")\n",
        "    try:\n",
        "        txt = transcribe_with_whisper(Path(test_file))\n",
        "        print(\"=== Transcript ===\")\n",
        "        print(txt if isinstance(txt, str) else str(txt))\n",
        "    except Exception as e:\n",
        "        print(\"Transcription failed:\", e)\n",
        "else:\n",
        "    print(\"No audio file found for smoke test.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Troubleshooting\n",
        "- **Port & reachability**: Confirm `:8080` and that this notebook can reach `whisper-...svc.cluster.local`.\n",
        "- **Auth**: If your gateway requires a token, export `OPENAI_API_KEY` and re-run the config cell.\n",
        "- **Server errors**: Consider printing `resp.text` on non-2xx responses inside `transcribe_with_whisper` for more detail.\n",
        "- **Large files**: Increase `timeout` in `transcribe_with_whisper` as needed."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}